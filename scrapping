from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options 
from webdriver_manager.chrome import ChromeDriverManager
import time
import csv

# --- CONFIGURATION DU DRIVER ---
options = webdriver.ChromeOptions()

# 1. Mode Headless (Le script tourne en fond sans fenêtre)
# On utilise "=new" car c'est la version moderne qui imite parfaitement un vrai navigateur
options.add_argument("--headless=new") 

# 2. Taille de fenêtre (OBLIGATOIRE en headless)
# Sans ça, Steam peut ne pas charger les éléments car il pense que la fenêtre est minuscule
options.add_argument("--window-size=1920,1080")

# 3. User-Agent (Pour ne pas se faire repérer)
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
options.add_argument(f'user-agent={user_agent}')

# 4. Anti-détection bot
options.add_argument("--disable-blink-features=AutomationControlled")

# 5. On lance le driver avec toutes ces options
print("Lancement du scraper en arrière-plan (Headless)...")
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

driver.get("https://store.steampowered.com")

accept_button = WebDriverWait(driver, 10).until(
    EC.element_to_be_clickable((By.ID, "acceptAllButton"))
)
accept_button.click()

bouton_parcourir = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'Parcourir')]"))
    )
bouton_parcourir.click()

bouton_promo = WebDriverWait(driver, 10).until(
    EC.element_to_be_clickable((By.XPATH, "//a[contains(@href, 'specials')]"))
)
bouton_promo.click()

# Fonction pour scroller la page
def scroll_page(driver, scrolls=3, pause_time=1):
    """Scroll la page pour charger plus de jeux"""
    for i in range(scrolls):
        # Scroll vers le bas
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        print(f"Scroll {i+1}/{scrolls}")
        time.sleep(pause_time)

# --- CONFIGURATION DU CHARGEMENT ---
nombre_de_tours = 3  # <--- Change ce chiffre pour cliquer plus ou moins de fois

print(f"Début du chargement étendu : {nombre_de_tours} tours prévus.")

for i in range(nombre_de_tours):
    print(f"--- Tour {i+1} / {nombre_de_tours} ---")
    
    # 1. On scrolle vers le bas pour atteindre le bouton
    scroll_page(driver, scrolls=3, pause_time=1)
    
    try:
        # 2. On essaie de trouver et cliquer sur le bouton
        bouton_afficherplus = WebDriverWait(driver, 5).until(
            EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'Afficher plus')]"))
        )
        bouton_afficherplus.click()
        print("✅ Bouton 'Afficher plus' cliqué !")
        
        # 3. Pause importante pour laisser le temps aux nouveaux jeux d'arriver
        time.sleep(3)
        
    except:
        # Si le bouton n'est pas trouvé (ex: fin de la liste), on arrête proprement
        print("⚠️ Bouton non trouvé ou fin de page atteinte. Arrêt de la boucle.")
        break

# Un dernier scroll final pour être sûr de bien charger toutes les images des derniers jeux
print("Scroll final...")
scroll_page(driver, scrolls=3, pause_time=1)

# on veut le titre le prix original e prix réduit la réduction et l'évaluation.

# 1. On récupère TOUTES les boîtes de jeux (les parents)
# On utilise find_elements (avec un 's') pour avoir une liste
# On cible d'abord le conteneur PRINCIPAL (sale_item_browser)
# Puis on cherche les jeux (ImpressionTrackedElement) à l'intérieur
liste_jeux = driver.find_elements(By.XPATH, "//div[contains(@class, 'sale_item_browser')]//div[contains(@class, 'ImpressionTrackedElement')]")

print(f"Nombre de jeux trouvés (filtrés) : {len(liste_jeux)}")

with open('jeux_steam.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)

    writer.writerow(["Titre", "Infos Prix", "Avis", "Résumé", "Tags", "Lien"])   
    
    # 2. On boucle sur chaque "boîte" une par une
    for jeu in liste_jeux:
        print("------------------------------------------------")
        try:
         # --- TITRE ---
            # ⚠️ ATTENTION AU POINT "." AU DÉBUT DU XPATH !
         # Le "." signifie "Cherche à l'intérieur de 'jeu', pas dans toute la page"
            titre = jeu.find_element(By.XPATH, ".//img").get_attribute("alt")
        except:
            titre = "Titre inconnu"

        try:
            # --- PRIX ---
            # On cherche la div de prix À L'INTÉRIEUR de la variable 'jeu'
            infos_prix = jeu.find_element(By.XPATH, ".//div[contains(@class, 'StoreSalePriceWidgetContainer')]").get_attribute("aria-label")
        except:
            infos_prix = "Pas de prix / Gratuit"

        try:
            # --- ÉVALUATION ---
            # Idem, on cherche l'avis À L'INTÉRIEUR de 'jeu'
            infos_eval = jeu.find_element(By.XPATH, ".//a[contains(@class, 'ReviewScore')]//div[@aria-label]").get_attribute("aria-label")
        except:
            infos_eval = "Pas d'évaluation"

        try:
            # --- RÉSUMÉ ---
            # On cherche la div dont la classe contient 'StoreSaleWidgetShortDesc'
            resume = jeu.find_element(By.XPATH, ".//div[contains(@class, 'StoreSaleWidgetShortDesc')]").text
        except:
            resume = "Pas de résumé disponible"
        
        try:
            # --- TAGS ---
            elements_tags = jeu.find_elements(By.XPATH, ".//a[contains(@href, '/tags/')]")
            
            # CORRECTION MAJEURE ICI :
            # 1. On utilise .get_attribute("textContent") au lieu de .text pour lire même les tags cachés
            # 2. On ajoute .strip() pour nettoyer les espaces
            # 3. On filtre (if tag) pour virer les vides s'il y en a encore
            
            liste_tags_propre = [t.get_attribute("textContent").strip() for t in elements_tags]
            liste_tags_propre = [tag for tag in liste_tags_propre if tag] # garde l'élément seulement s'il contient quelque chose
            
            # On extrait le texte de chaque balise trouvée
            # Et on les rejoint avec une virgule (ex: "RPG, Aventure, Action")
            tags = ", ".join(liste_tags_propre)
            
            if not tags:
                tags = "Aucun tag"
                
        except:
            tags = "Erreur récupération tags"
        
        try:
            # --- LIEN DU JEU ---
            # On cherche la balise <a> qui contient "/app/" dans son lien
            lien = jeu.find_element(By.XPATH, ".//a[contains(@href, '/app/')]").get_attribute("href")
            
            # (Optionnel) Nettoyage : On enlève les paramètres de tracking "?snr=..." si tu veux un lien propre
            if "?" in lien:
                lien = lien.split("?")[0]
                
        except:
            lien = "Pas de lien trouvé"

        # Affichage des résultats liés
        print(f"Jeu : {titre}")
        print(f"Prix : {infos_prix}")
        print(f"Avis : {infos_eval}")
        print(f"Résumé : {resume}")
        print(f"Tags : {tags}")
        writer.writerow([titre, infos_prix, infos_eval, resume, tags, lien])
        print(f"Sauvegardé : {titre}")

print("--- FIN DU SCRAPING ---")
